{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11eed0ab6d5c4519b5f376550a9f1627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='70%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation text:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab14d205aed4e669e9702cfca8297e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='70%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "Writing to ../data/train_buffer.tmp\n",
      "Wrote: When I lived in *Paris last year, *France was experiencing a recession. The night life was too fun, I developed an addiction to !Adderall and !cocaine\n",
      "============\n",
      "============\n",
      "Writing to ../data/validate_buffer.tmp\n",
      "Wrote: I lived in Munich last summer. Germany has a relaxing, slow summer lifestyle. One night, I got food poisoning and couldn't find Tylenol to make the pain go away, they insisted I take aspirin instead\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "from allennlp.common.params import Params\n",
    "from allennlp.commands.train import train_model\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import Textarea, VBox, HBox, Layout, widgets\n",
    "\n",
    "from model import InstEntityTagger\n",
    "from predictor import InstPredictor\n",
    "from dataset_reader import InstDatasetReader\n",
    "\n",
    "# Global variables.\n",
    "TRAIN_BUFFER_PATH = \"../data/train_buffer.tmp\"\n",
    "VALIDATION_BUFFER_PATH = \"../data/validate_buffer.tmp\"\n",
    "TRAIN_DONE = False\n",
    "VALIDATION_DONE = False\n",
    "\n",
    "def train_prompt():\n",
    "    train_text = widgets.Text(layout=Layout(width='70%'))\n",
    "    print(\"Training text:\")\n",
    "    display(train_text)\n",
    "    train_text.on_submit(read_train)\n",
    "    \n",
    "def validation_prompt():\n",
    "    valid_text = widgets.Text(layout=Layout(width='70%'))\n",
    "    print(\"Validation text:\")\n",
    "    display(valid_text)\n",
    "    valid_text.on_submit(read_validation)\n",
    "\n",
    "def read_train(sender):\n",
    "    global TRAIN_DONE\n",
    "    assert os.path.exists(\"../data/\") # Avoid absolute paths?\n",
    "    # assert not os.path.isfile(TRAIN_BUFFER_PATH)\n",
    "    with open(TRAIN_BUFFER_PATH, 'w') as train_file:\n",
    "        train_file.write(sender.value)\n",
    "    print(\"============\")\n",
    "    print(\"Writing to\", TRAIN_BUFFER_PATH)\n",
    "    print(\"Wrote:\", sender.value)\n",
    "    print(\"============\")\n",
    "    TRAIN_DONE = True\n",
    "    \n",
    "def read_validation(sender):\n",
    "    global VALIDATION_DONE\n",
    "    assert os.path.exists(\"../data/\") # Avoid absolute paths?\n",
    "    # assert not os.path.isfile(TRAIN_BUFFER_PATH)\n",
    "    with open(VALIDATION_BUFFER_PATH, 'w') as valid_file:\n",
    "        valid_file.write(sender.value)\n",
    "    print(\"============\")\n",
    "    print(\"Writing to\", VALIDATION_BUFFER_PATH)\n",
    "    print(\"Wrote:\", sender.value)\n",
    "    print(\"============\")\n",
    "    VALIDATION_DONE = True\n",
    "    \n",
    "def set_params(train_buffer_path: str, validation_buffer_path: str) -> Params:\n",
    "    # Modifying parameter values\n",
    "    params = Params.from_file('template.jsonnet')\n",
    "    params.__setitem__(\"train_data_path\", train_buffer_path)\n",
    "    params.__setitem__(\"validation_data_path\", validation_buffer_path)\n",
    "    # print(json.dumps(params.as_dict(), indent=4))\n",
    "    return params\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_prompt()\n",
    "    validation_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 63.09it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 63.10it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "2it [00:00, 304.98it/s]\n",
      "\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]\n",
      "100%|##########| 500000/500000 [00:07<00:00, 64685.12it/s]\n",
      "\n",
      "  0%|          | 0/500000 [00:00<?, ?it/s]\n",
      "100%|##########| 500000/500000 [00:07<00:00, 68398.20it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "accuracy: 0.8621, loss: 0.9244 ||: 100%|##########| 1/1 [00:00<00:00, 22.76it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "accuracy: 0.8537, loss: 0.9700 ||: 100%|##########| 1/1 [00:00<00:00, 48.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_I\n",
      "_lived\n",
      "_in\n",
      "*Munich\n",
      "_last\n",
      "_summer\n",
      "_.\n",
      "*Germany\n",
      "_has\n",
      "_a\n",
      "_relaxing\n",
      "_,\n",
      "_slow\n",
      "_summer\n",
      "_lifestyle\n",
      "_.\n",
      "_One\n",
      "_night\n",
      "_,\n",
      "_I\n",
      "_got\n",
      "!food\n",
      "_poisoning\n",
      "_and\n",
      "_could\n",
      "*n't\n",
      "_find\n",
      "!Tylenol\n",
      "_to\n",
      "_make\n",
      "_the\n",
      "_pain\n",
      "_go\n",
      "_away\n",
      "_,\n",
      "_they\n",
      "_insisted\n",
      "_I\n",
      "_take\n",
      "!aspirin\n",
      "_instead\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    assert TRAIN_DONE and VALIDATION_DONE\n",
    "    params = set_params(TRAIN_BUFFER_PATH, VALIDATION_BUFFER_PATH)\n",
    "    \n",
    "    parms = params.duplicate()\n",
    "    serialization_dir = tempfile.mkdtemp()\n",
    "    model = train_model(params, serialization_dir)\n",
    "\n",
    "    predpath = parms.pop(key=\"validation_data_path\")\n",
    "\n",
    "    # Make predictions\n",
    "    predictor = InstPredictor(model, dataset_reader=InstDatasetReader())\n",
    "    with open(predpath, \"r\") as text_file:\n",
    "        lines = text_file.readlines()\n",
    "    all_text = \" \".join(lines) # Makes it all 1 batch.\n",
    "    output_dict = predictor.predict(all_text)\n",
    "    tags = output_dict['tags']\n",
    "    dataset_reader = InstDatasetReader()\n",
    "    \n",
    "    PRINT_STDOUT = True\n",
    "    \n",
    "    with open(\"log.log\", 'a') as log:\n",
    "        for instance in dataset_reader._read(predpath):\n",
    "            tokenlist = list(instance['sentence'])\n",
    "            for i, token in enumerate(tokenlist):\n",
    "                log.write(tags[i] + str(token) + \"\\n\")\n",
    "                if PRINT_STDOUT:\n",
    "                    print(tags[i] + str(token))\n",
    "    shutil.rmtree(serialization_dir)\n",
    "    print(\"DONE.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
